{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised learning Capstone (name TBA)\n",
    "Author: Matthew Huh\n",
    "    \n",
    "## Overview\n",
    "\n",
    "For the most part, people are free to choose what news outlets they read and follow. In the United States, there is a near-endless list of sites that people can choose from in order to get their daily news and over time, they develop preferences for sites that they are more attached to, and do their best to avoid. Now these affinities are developed through a combination of means ranging from affiliations, vocabulary, prose, and so forth.\n",
    "\n",
    "What I would like to examine in this project is if it is possible to differentiate from several different publications with their respective perks / quirks. \n",
    "\n",
    "## About the Data\n",
    "\n",
    "This dataset was obtained from Kaggle, and contains a collection of 142,570 articles from 15 different publications.\n",
    "\n",
    "The publications within this dataset are\n",
    "1. CNN\n",
    "2. Breitbart\n",
    "3. Vox\n",
    "4. Washington Post\n",
    "5. New York Post\n",
    "6. National Review\n",
    "7. NPR\n",
    "8. Guardian\n",
    "9. Talking Points Memo\n",
    "10. Atlantic\n",
    "11. Reuters\n",
    "12. Fox News\n",
    "13. Business Insider\n",
    "14. Buzzfeed News\n",
    "15. New York Times\n",
    "\n",
    "## Research Question\n",
    "\n",
    "As this is an unsupervised learning project first and foremost, the project will have 3 goals.\n",
    "\n",
    "1. The first goal is to prepare the articles in the dataset for modelling using various Natural Language Processing (NLP) methods to re-represent the data in numbers rather than words\n",
    "2. Cluster the data to determine if we can identify the articles and associate them as different groups.\n",
    "3. Determine if we can predict the structure of the article based on the publisher.\n",
    "\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning packages\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Clustering packages\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Natural Language processing\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_rcv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preview\n",
    "\n",
    "The first matter of business is to import the articles from a local directory and merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2           2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "\n",
       "      publication                         author        date    year  month  \\\n",
       "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
       "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
       "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
       "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
       "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
       "\n",
       "   url                                            content  \n",
       "0  NaN  WASHINGTON  —   Congressional Republicans have...  \n",
       "1  NaN  After the bullet shells get counted, the blood...  \n",
       "2  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3  NaN  Death may be the great equalizer, but it isn’t...  \n",
       "4  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of files from directory\n",
    "filelist = os.listdir('articles')\n",
    "\n",
    "# Import the files\n",
    "df_list = [pd.read_csv(file) for file in filelist]\n",
    "\n",
    "#concatenate them together\n",
    "articles = pd.concat(df_list)\n",
    "\n",
    "# Preview the data\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142570, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the size of the dataset\n",
    "articles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 142,570 articles in the dataset but unfortunately, NLP is quite memory intensive, so we will have to sample the dataset unless you happen to have over 120 GB of memory on your local device. Using a 10% sample still leaves us with 140,000 articles and will be used for the duration of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the dataset for optimal performance\n",
    "articles = articles.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buzzfeed News', 'New York Post', 'Vox', 'Washington Post',\n",
       "       'Breitbart', 'NPR', 'CNN', 'Guardian', 'National Review',\n",
       "       'Fox News', 'Talking Points Memo', 'Business Insider', 'Atlantic',\n",
       "       'Reuters', 'New York Times'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out unique publisher names\n",
    "articles.publication.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          14251\n",
       "publication       15\n",
       "author          3936\n",
       "date            1036\n",
       "url             8476\n",
       "content        14248\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe unique occurences for each categorical variable\n",
    "articles.select_dtypes(include=['object']).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also other ways to trim down the dataset before processing. We aren't particularly interested in examining the dates for this research question, but it may be of interest in another. Let's check to see how many articles each author wrote; it may not be very useful to examine authors that are only responsible for a single article, as different authors from the same publisher may choose compose their works differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables that have no impact on the outcome\n",
    "articles = articles[['title', 'publication', 'author', 'content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Breitbart News                                       151\n",
       "Pam Key                                              146\n",
       "Associated Press                                     126\n",
       "Charlie Spiering                                     115\n",
       "Jerome Hudson                                         94\n",
       "Joel B. Pollak                                        74\n",
       "John Hayward                                          74\n",
       "AWR Hawkins                                           73\n",
       "Daniel Nussbaum                                       67\n",
       "Alex Swoyer                                           57\n",
       "Ian Hanchett                                          56\n",
       "Warner Todd Huston                                    53\n",
       "Post Editorial Board                                  49\n",
       "David A. Graham                                       46\n",
       "Merrit Kennedy                                        44\n",
       "Katherine Rodriguez                                   44\n",
       "Jeff Poor                                             44\n",
       "NPR Staff                                             44\n",
       "Camila Domonoske                                      43\n",
       "Dr. Susan Berry                                       40\n",
       "Frances Martel                                        40\n",
       "Claire Atkinson                                       39\n",
       "Bob Price                                             39\n",
       "Trent Baker                                           39\n",
       "Breitbart Jerusalem                                   38\n",
       "Josh Marshall                                         38\n",
       "Reuters                                               37\n",
       "German Lopez                                          37\n",
       "Bill Chappell                                         36\n",
       "Dan Riehl                                             36\n",
       "                                                    ... \n",
       "Lawrence Delevingne                                    1\n",
       "Lavanya Ramanathan                                     1\n",
       "Laurie Goodstein and Anemona Hartocollis               1\n",
       "Lauren Wiseman                                         1\n",
       "Lauren Wilson, News.com.au                             1\n",
       "Lauren Hirsch, Clara Denina  and Hadeel Al Sayegh      1\n",
       "Lee Hale                                               1\n",
       "Leika Kihara                                           1\n",
       "Linsey McGoey                                          1\n",
       "Leila Fadel                                            1\n",
       "Lindsay Dodgson                                        1\n",
       "Linda Tripp                                            1\n",
       "Linda Massarella and Chris Perez                       1\n",
       "Linda Kinstler                                         1\n",
       "Lin Noueihed                                           1\n",
       "Lily Koppel                                            1\n",
       "Libby Kane                                             1\n",
       "Liana B. Baker and Sai Sachin R                        1\n",
       "Liana B. Baker and Lauren Hirsch                       1\n",
       "Liana B. Baker and Jim Finkle                          1\n",
       "Liana B. Baker and Greg Roumeliotis                    1\n",
       "Lia Eustachewich and Reuven Fenton                     1\n",
       "Lia Eustachewich and Priscilla DeGregory               1\n",
       "Leslie Wylie                                           1\n",
       "Leslie Picker and Reed Abelson                         1\n",
       "Lesley Wroughton and Matt Spetalnick                   1\n",
       "Lesley Wroughton                                       1\n",
       "Leonica Valentine and Sarah Trefethen                  1\n",
       "Lenika Cruz                                            1\n",
       " Danielle Rossingh                                     1\n",
       "Length: 3936, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View most frequently occurring authors\n",
    "articles.groupby(['author']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that partly explains how there are so many authors in this dataset. It seems as though there are over 15,000 authors, and many of them have only published one article, or have co-written multiple articles with other authors. This complicates the problem, so in order to best represent each author's writing style, let's see what happens if we simply remove all authors that only published one article as is.\n",
    "\n",
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop author from the dataframe if they wrote less than 5 articles\n",
    "vc = articles['author'].value_counts()\n",
    "u  = [i not in set(vc[vc<=4].index) for i in articles['author']]\n",
    "articles = articles[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          9354\n",
       "publication      15\n",
       "author          605\n",
       "content        9351\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reprint how many unique authors there are\n",
    "articles.select_dtypes(include=['object']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9360, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View number of articles after feature selection\n",
    "articles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after removing authors that composed fewer than 5 articles, we are left with 9k articles, or 67% of the data, and roughly 600/3900 of the authors. Now, we can create a better representation of each author since each author has at least 5 articles to evaluate from.\n",
    "\n",
    "## Text Cleaning\n",
    "\n",
    "Now that we've chosen which articles to use, it's time to clean them up and prepare them for feature engineering. What this section covers is the removal of annoying punctuation from the content, and reducing words to their lemmas to reduce the number of words that we are examining. Finally, we'll divide the articles into training and testing sets and separate our predictor, the words in the content, and the target, the publisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16755</th>\n",
       "      <td>People Are Laughing/Screaming Over This Sex T...</td>\n",
       "      <td>Buzzfeed News</td>\n",
       "      <td>Julia Reinstein</td>\n",
       "      <td>’ This is the Sqweel 2, an oral sex simulator ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>One Child Has Died And Five Others Were Injur...</td>\n",
       "      <td>Buzzfeed News</td>\n",
       "      <td>Salvador Hernandez</td>\n",
       "      <td>Emergency crews on scene at Quality Inn in Nil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42797</th>\n",
       "      <td>Woman who pushed husband out of high-rise wind...</td>\n",
       "      <td>New York Post</td>\n",
       "      <td>Natalie Musumeci</td>\n",
       "      <td>An Oklahoma woman convicted of murder for shov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28777</th>\n",
       "      <td>Watch: Trump-Clinton final presidential debate...</td>\n",
       "      <td>Vox</td>\n",
       "      <td>Andrew Prokop</td>\n",
       "      <td>The third and at long last final general elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33449</th>\n",
       "      <td>Please, can someone brief the president on the...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>Glenn Kessler</td>\n",
       "      <td>“When you look for a job, you can’t find it an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title      publication  \\\n",
       "16755   People Are Laughing/Screaming Over This Sex T...    Buzzfeed News   \n",
       "17377   One Child Has Died And Five Others Were Injur...    Buzzfeed News   \n",
       "42797  Woman who pushed husband out of high-rise wind...    New York Post   \n",
       "28777  Watch: Trump-Clinton final presidential debate...              Vox   \n",
       "33449  Please, can someone brief the president on the...  Washington Post   \n",
       "\n",
       "                   author                                            content  \n",
       "16755     Julia Reinstein  ’ This is the Sqweel 2, an oral sex simulator ...  \n",
       "17377  Salvador Hernandez  Emergency crews on scene at Quality Inn in Nil...  \n",
       "42797    Natalie Musumeci  An Oklahoma woman convicted of murder for shov...  \n",
       "28777       Andrew Prokop  The third and at long last final general elect...  \n",
       "33449       Glenn Kessler  “When you look for a job, you can’t find it an...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove annoying punctuation from the articles\n",
    "articles['content'] = articles.content.map(lambda x: text_cleaner(str(x)))\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Reduce all text to their lemmas\n",
    "for article in articles['content']:\n",
    "    article = lemmatizer.lemmatize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify predictor and target variables\n",
    "X = articles['content']\n",
    "y = articles['publication']\n",
    "\n",
    "# Create training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf Vectorization\n",
    "\n",
    "The first types of features that we are going to add are the most useful words in our dataset. Now how are we going to determine which words are deemed the most \"useful\"? With TF-IDF vectorizer, of course.\n",
    "\n",
    "TF tracks the term frequency, or how often each word appears in all articles of text, while idf (or Inverse Document Frequency) is a value that places less weight on variables that occur too often and lose their predictive power. Put together, it's a tool that allows us to assign an importance value to each word in the entire dataset based on frequency in each row and throughout the database.\n",
    "\n",
    "These are the parameters that will be used for TF-IDF\n",
    "1. ll words that appear in over half of the articles will be thrown out of the dataframe\n",
    "2. Only words that occur more than 5 times will be tracked\n",
    "3. Only the top 150 features (words) will be kept\n",
    "4. Stop words will be ignored (like, as, the)\n",
    "5. Cases will be ignored\n",
    "6. Shorter and longer articles will be treated equally\n",
    "7. Add 1 to document frequency in case we have to divide by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,\n",
    "                             min_df=5, \n",
    "                             max_features=150, \n",
    "                             stop_words='english', \n",
    "                             lowercase=True, )\n",
    "                             use_idf=True,\n",
    "                             norm=u'l2',\n",
    "                             smooth_idf=True\n",
    "                            )\n",
    "\n",
    "#Applying the vectorizer\n",
    "X_tfidf=vectorizer.fit_transform(X)\n",
    "print(\"Number of features: %d\" % X_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#Removes all zeros from the matrix\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "# Normalize the dataset    \n",
    "X_norm = normalize(X_train_tfidf)\n",
    "\n",
    "# Convert from tf-idf matrix to dataframe\n",
    "X_normal  = pd.DataFrame(data=X_norm.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase count with spacy\n",
    "\n",
    "The second set of variables that we will be creating are counters of how often each publishers makes use of each part of speech, meaning adverbs, verbs, nouns, adjectives, as well as article length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating spaCy\n",
    "nlp = spacy.load('en')\n",
    "X_train_words = []\n",
    "\n",
    "for row in X_train:\n",
    "    # Processing each row for tokens\n",
    "    row_doc = nlp(row)\n",
    "    # Calculating length of each sentence\n",
    "    sent_len = len(row_doc) \n",
    "    # Initializing counts of different parts of speech\n",
    "    advs = 0\n",
    "    verb = 0\n",
    "    noun = 0\n",
    "    adj = 0\n",
    "    for token in row_doc:\n",
    "        # Identifying each part of speech and adding to counts\n",
    "        if token.pos_ == 'ADV':\n",
    "            advs +=1\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verb +=1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            noun +=1\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            adj +=1\n",
    "    # Creating a list of all features for each sentence\n",
    "    X_train_words.append([row_doc, advs, verb, noun, adj, sent_len])\n",
    "\n",
    "# Create dataframe with count of adverbs, verbs, nouns, and adjectives\n",
    "X_count = pd.DataFrame(data=X_train_words, columns=['BOW', 'ADV', 'VERB', 'NOUN', 'ADJ', 'sent_length'])\n",
    "\n",
    "# Change token count to token percentage\n",
    "for column in X_count.columns[1:5]:\n",
    "    X_count[column] = X_count[column] / X_count['sent_length']\n",
    "\n",
    "# Normalize X_count\n",
    "X_counter = normalize(X_count.drop('BOW',axis=1))\n",
    "X_counter  = pd.DataFrame(data=X_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141409</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.08767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172890</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.15818</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4    0         1         2    \\\n",
       "0  0.000029  0.000172  0.000284  0.000087  1.000000  0.0  0.000000  0.073068   \n",
       "1  0.000093  0.000361  0.000467  0.000220  1.000000  0.0  0.000000  0.000000   \n",
       "2  0.000103  0.000372  0.000526  0.000263  1.000000  0.0  0.000000  0.517905   \n",
       "3  0.000149  0.000810  0.000711  0.000264  0.999999  0.0  0.000000  0.054353   \n",
       "4  0.000082  0.000309  0.000367  0.000192  1.000000  0.0  0.112104  0.000000   \n",
       "\n",
       "   3         4     ...     140       141  142       143  144  145       146  \\\n",
       "0  0.0  0.000000   ...     0.0  0.233627  0.0  0.000000  0.0  0.0  0.000000   \n",
       "1  0.0  0.000000   ...     0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2  0.0  0.215882   ...     0.0  0.000000  0.0  0.000000  0.0  0.0  0.190630   \n",
       "3  0.0  0.000000   ...     0.0  0.000000  0.0  0.147398  0.0  0.0  0.000000   \n",
       "4  0.0  0.000000   ...     0.0  0.000000  0.0  0.000000  0.0  0.0  0.105358   \n",
       "\n",
       "        147      148      149  \n",
       "0  0.141409  0.00000  0.08767  \n",
       "1  0.172890  0.00000  0.00000  \n",
       "2  0.000000  0.15818  0.00000  \n",
       "3  0.000000  0.00000  0.00000  \n",
       "4  0.000000  0.00000  0.00000  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine tf-idf matrix and phrase count matrix\n",
    "features = pd.concat([X_counter,X_normal], ignore_index=False, axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we have our list of features. It doesn't look anything like our original dataset, now does it? \n",
    "\n",
    "# Clustering\n",
    "\n",
    "Now it's finally time for some unsupervised machine learning. Each article has been binarized to 1s and 0s, and it's time to determine if we can determine if each publisher has a different method for publication.\n",
    "\n",
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atlantic</th>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>117</td>\n",
       "      <td>13</td>\n",
       "      <td>73</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>343</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>109</td>\n",
       "      <td>57</td>\n",
       "      <td>97</td>\n",
       "      <td>129</td>\n",
       "      <td>32</td>\n",
       "      <td>268</td>\n",
       "      <td>90</td>\n",
       "      <td>176</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>191</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider</th>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buzzfeed News</th>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>144</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>90</td>\n",
       "      <td>22</td>\n",
       "      <td>81</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox News</th>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guardian</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPR</th>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Review</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Post</th>\n",
       "      <td>161</td>\n",
       "      <td>39</td>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>231</td>\n",
       "      <td>128</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>54</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Times</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talking Points Memo</th>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vox</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Post</th>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0                 0   1   2    3   4   5    6    7    8   9    10  11  12  \\\n",
       "publication                                                                     \n",
       "Atlantic              27  13  21   22   2  28  117   13   73  24   50  11  17   \n",
       "Breitbart            343  33  15  109  57  97  129   32  268  90  176  57  37   \n",
       "Business Insider      85   7  11   18   8  15   61   72   83  15   25  14   0   \n",
       "Buzzfeed News         42  17   4   22   1   6   22   19   27   2   28  10   0   \n",
       "CNN                  144  21  14   54   3  29   69   12   90  22   81  29   1   \n",
       "Fox News              49   9   9   24  13  12   11    5   35   6   23  10   6   \n",
       "Guardian              27  11   5   10   0   7   64   12   54   8   39  18   0   \n",
       "NPR                   39  20  92   25   6  22   85   12   48  13   51  13  11   \n",
       "National Review       10  10   3    8  13  31   47    1   52  20   26   1  13   \n",
       "New York Post        161  39  69   62   4  13  231  128   74  18   54  67  49   \n",
       "New York Times        10   6   0    3   0   2   11    4   11   4   15   5   2   \n",
       "Reuters                2   6   0    0   2  10    3    7    6   6   14   1  47   \n",
       "Talking Points Memo   64  18   0   12  17  58   21    4  119  17   30   3   8   \n",
       "Vox                   10   6   9    4   5  26   85   10   52  12   32   0  17   \n",
       "Washington Post       49  13   1   20  11  44   25    5  128  22   55  11   7   \n",
       "\n",
       "col_0                 13  14  \n",
       "publication                   \n",
       "Atlantic              20  12  \n",
       "Breitbart            191  47  \n",
       "Business Insider      28   4  \n",
       "Buzzfeed News          6  10  \n",
       "CNN                   34  25  \n",
       "Fox News              46   2  \n",
       "Guardian               7  10  \n",
       "NPR                   21  14  \n",
       "National Review       23   3  \n",
       "New York Post         25  21  \n",
       "New York Times         2   1  \n",
       "Reuters                0   0  \n",
       "Talking Points Memo   22   4  \n",
       "Vox                   22  16  \n",
       "Washington Post       34  11  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calulate predicted values\n",
    "kmeans = KMeans(n_clusters=15, init='k-means++', random_state=42, n_init=20)\n",
    "y_pred = kmeans.fit_predict(features)\n",
    "\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.02276652\n",
      "Silhouette Score: 0.0677047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "print('Adjusted Rand Score: {:0.7}'.format(adjusted_rand_score(y_train, y_pred)))\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(features, y_pred, sample_size=60000, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atlantic</th>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>100</td>\n",
       "      <td>108</td>\n",
       "      <td>83</td>\n",
       "      <td>29</td>\n",
       "      <td>144</td>\n",
       "      <td>30</td>\n",
       "      <td>88</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>232</td>\n",
       "      <td>168</td>\n",
       "      <td>399</td>\n",
       "      <td>161</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider</th>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buzzfeed News</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>142</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox News</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guardian</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPR</th>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>75</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Review</th>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Post</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>109</td>\n",
       "      <td>129</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>102</td>\n",
       "      <td>22</td>\n",
       "      <td>120</td>\n",
       "      <td>249</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Times</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talking Points Memo</th>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>83</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vox</th>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Post</th>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>93</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0                 0    1    2    3    4   5   6   7   8    9    10   11  \\\n",
       "publication                                                                   \n",
       "Atlantic              33   30   38   15   50  14  17  11  13   56   20   26   \n",
       "Breitbart            100  108   83   29  144  30  88  30  47  232  168  399   \n",
       "Business Insider      26   21   29   67   48   6  16   0   4   50   22   71   \n",
       "Buzzfeed News          8    4   12   19   16  18  17   0  10   44    6   37   \n",
       "CNN                   39   30   43    8   60  23  41   0  25  142   30   95   \n",
       "Fox News              18    7    8    4   23   8  23   6   1   51   39   44   \n",
       "Guardian               8    9   24   11   39  11  10   0  10   48    6   23   \n",
       "NPR                   28   23   25   11   25  21  20   6  13   75   17   28   \n",
       "National Review       35   28    6    1   34  12   6  11   2   30   18   10   \n",
       "New York Post         24   24  109  129   47  30  52  34  18  102   22  120   \n",
       "New York Times         2    5    8    2    7   7   2   1   1   17    2   10   \n",
       "Reuters               14    7    3    8    2   6   0  45   0   14    0    0   \n",
       "Talking Points Memo   69   23   11    3   71  18   7   5   3   41   18   83   \n",
       "Vox                   28   17    7    9   35   8   4  12  16   40   21   19   \n",
       "Washington Post       52   27   15    5   93  17  18   9  11   66   36   41   \n",
       "\n",
       "col_0                 12  13  14  \n",
       "publication                       \n",
       "Atlantic             110  16   1  \n",
       "Breitbart            161   9  53  \n",
       "Business Insider      70   7   9  \n",
       "Buzzfeed News         21   3   1  \n",
       "CNN                   78  11   3  \n",
       "Fox News              10   7  11  \n",
       "Guardian              68   5   0  \n",
       "NPR                   87  88   5  \n",
       "National Review       54   2  12  \n",
       "New York Post        249  52   3  \n",
       "New York Times        12   0   0  \n",
       "Reuters                3   0   2  \n",
       "Talking Points Memo   32   1  12  \n",
       "Vox                   78   7   5  \n",
       "Washington Post       34   0  12  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SpectralClustering(n_clusters=15)\n",
    "y_pred2 = sc.fit_predict(features)\n",
    "\n",
    "pd.crosstab(y_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.02637186\n",
      "Silhouette Score: 0.05386364\n"
     ]
    }
   ],
   "source": [
    "print('Adjusted Rand Score: {:0.7}'.format(adjusted_rand_score(y_train, y_pred2)))\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(features, y_pred2, sample_size=60000, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atlantic</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buzzfeed News</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox News</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guardian</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPR</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Review</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Post</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Times</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talking Points Memo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vox</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Post</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0                0    1    2    3    4    5    6    7    8    9   ...   \\\n",
       "publication                                                           ...    \n",
       "Atlantic               4    2    0    9    1    0    3    0    0    1 ...    \n",
       "Breitbart              0    8    0   18    8    1    3    2    9    7 ...    \n",
       "Business Insider       0    0    0    4    1    2    0    1    0    0 ...    \n",
       "Buzzfeed News          0    0    0    5    0    0    0    2    0    3 ...    \n",
       "CNN                    0    2    2   22    1    0    2    2    0    5 ...    \n",
       "Fox News               0    0    0    4    2    0    2    2    0    2 ...    \n",
       "Guardian               0    0    5    3    0    0    0    0    0    2 ...    \n",
       "NPR                    0    2    0    6    1    0    0    0    0    2 ...    \n",
       "National Review        0    0    0    1    0    0    0    0    0    0 ...    \n",
       "New York Post          0    1   11    9    8    3    2    0    0    1 ...    \n",
       "New York Times         0    0    0    0    0    0    0    1    0    0 ...    \n",
       "Reuters                0    0    0    0    0    0    0    0    0    0 ...    \n",
       "Talking Points Memo    0    0    0    1    0    1    2    0    0    0 ...    \n",
       "Vox                    1    1    0    1    0    0    1    0    0    0 ...    \n",
       "Washington Post        0    1    0    2    0    0    1    0    1    1 ...    \n",
       "\n",
       "col_0                235  236  237  238  239  240  241  242  243  244  \n",
       "publication                                                            \n",
       "Atlantic               2    1    0    2    1    0    0    1    3    0  \n",
       "Breitbart              7    1    3    3    8    1    1    4    1    2  \n",
       "Business Insider       4    0    1    2    2    0    2    0    1    1  \n",
       "Buzzfeed News          3    1    0    3    0    1    1    2    1    0  \n",
       "CNN                    5    2    0    3    0    0    2    1    0    2  \n",
       "Fox News               1    0    1    1    0    1    1    0    0    0  \n",
       "Guardian               3    0    0    0    0    0    1    2    1    0  \n",
       "NPR                    1    4    0    2    1    0    0    0    1    2  \n",
       "National Review        2    0    0    0    0    0    0    2    1    0  \n",
       "New York Post          0    1    0    2    1   18    2    2    0    2  \n",
       "New York Times         0    0    0    1    2    0    0    0    0    1  \n",
       "Reuters                0    0    0    0    0    0    0    0    0    0  \n",
       "Talking Points Memo    2    0    2    8    2    0    1    1    8    1  \n",
       "Vox                    2    0    0    5    1    0    0    3    1    0  \n",
       "Washington Post        2    0    0    0    4    0    1    3    2    0  \n",
       "\n",
       "[15 rows x 245 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af = AffinityPropagation()\n",
    "y_pred3 = af.fit_predict(features)\n",
    "\n",
    "pd.crosstab(y_train, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.01183964\n",
      "Silhouette Score: 0.00831869\n"
     ]
    }
   ],
   "source": [
    "print('Adjusted Rand Score: {:0.7}'.format(adjusted_rand_score(y_train, y_pred3))\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(features, y_pred3, sample_size=60000, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rnadom forest classifier score: 0.40755(+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_train = cross_val_score(rfc, features, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "print('Random forest classifier score: {:.5f}(+/- {:.2f})'.format(rfc_train.mean(), rfc_train.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression score: 0.43960(+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_train = cross_val_score(lr, features, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "print('Logistic regression score: {:.5f}(+/- {:.2f})'.format(lr_train.mean(), lr_train.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting classifier score: 0.49074(+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc_train = cross_val_score(gbc, features, y_train, cv=5, n_jobs=-1)\n",
    "\n",
    "print('Gradient boosting classifier score: {:.5f}(+/- {:.2f})'.format(gbc_train.mean(), gbc_train.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'loss': 'deviance', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 12, 'n_estimators': 800}\n",
      "Best Score:\n",
      "0.5022792022792023\n"
     ]
    }
   ],
   "source": [
    "# Parameters for gradient boosting classifier\n",
    "param_grid  = {'loss':['deviance'],\n",
    "               'max_features': ['sqrt'],\n",
    "               'n_estimators': [400, 800],\n",
    "               'max_depth': [12, 20],\n",
    "               \"min_samples_leaf\" : [12, 20]}\n",
    "\n",
    "# Run grid search to find ideal parameters\n",
    "gbc_grid = GridSearchCV(gbc, param_grid = param_grid, n_jobs=-1)\n",
    "\n",
    "# Initialize and fit the model.\n",
    "gbc_grid.fit(features, y_train)\n",
    "\n",
    "# Return best parameters and best score\n",
    "print('Best parameters:')\n",
    "print(gbc_grid.best_params_)\n",
    "print('Best Score:')\n",
    "print(gbc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Tf-idf vectors\n",
    "X_test_norm = normalize(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_words = []\n",
    "\n",
    "for row in X_test:\n",
    "    # Processing each row for tokens\n",
    "    row_doc = nlp(row)\n",
    "    # Calculating length of each sentence\n",
    "    sent_len = len(row_doc) \n",
    "    # Initializing counts of different parts of speech\n",
    "    advs = 0\n",
    "    verb = 0\n",
    "    noun = 0\n",
    "    adj = 0\n",
    "    for token in row_doc:\n",
    "        # Identifying each part of speech and adding to counts\n",
    "        if token.pos_ == 'ADV':\n",
    "            advs +=1\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verb +=1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            noun +=1\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            adj +=1\n",
    "    # Creating a list of all features for each sentence\n",
    "    X_test_words.append([row_doc, advs, verb, noun, adj, sent_len])\n",
    "    \n",
    "# Data frame for features\n",
    "X_test_count = pd.DataFrame(data=X_test_words, columns=['BOW', 'ADV', 'VERB', 'NOUN', 'ADJ', 'sent_length'])\n",
    "\n",
    "# Change token count to token percentage\n",
    "for column in X_test_count.columns[1:5]:\n",
    "    X_test_count[column] = X_test_count[column] / X_test_count['sent_length']\n",
    "\n",
    "# Normalize X_count\n",
    "X_test_counter = normalize(X_test_count.drop('BOW',axis=1))\n",
    "X_test_counter  = pd.DataFrame(data=X_test_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081184</td>\n",
       "      <td>0.210982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171878</td>\n",
       "      <td>0.162751</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4    0    1         2    \\\n",
       "0  0.000028  0.000195  0.000313  0.000123  1.000000  0.0  0.0  0.081184   \n",
       "1  0.000084  0.000358  0.000308  0.000160  1.000000  0.0  0.0  0.444061   \n",
       "2  0.000078  0.000337  0.000380  0.000121  1.000000  0.0  0.0  0.000000   \n",
       "3  0.000127  0.000375  0.000487  0.000185  1.000000  0.0  0.0  0.117811   \n",
       "4  0.000203  0.001014  0.001251  0.000406  0.999999  0.0  0.0  0.000000   \n",
       "\n",
       "        3         4      ...     140  141       142  143       144       145  \\\n",
       "0  0.210982  0.000000    ...     0.0  0.0  0.000000  0.0  0.000000  0.000000   \n",
       "1  0.000000  0.111061    ...     0.0  0.0  0.100982  0.0  0.000000  0.000000   \n",
       "2  0.000000  0.000000    ...     0.0  0.0  0.254268  0.0  0.000000  0.125655   \n",
       "3  0.000000  0.000000    ...     0.0  0.0  0.133954  0.0  0.148515  0.000000   \n",
       "4  0.000000  0.000000    ...     0.0  0.0  0.000000  0.0  0.000000  0.000000   \n",
       "\n",
       "   146       147       148       149  \n",
       "0  0.0  0.000000  0.000000  0.194815  \n",
       "1  0.0  0.171878  0.162751  0.000000  \n",
       "2  0.0  0.000000  0.000000  0.000000  \n",
       "3  0.0  0.000000  0.000000  0.141354  \n",
       "4  0.0  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining features into one data frame\n",
    "X_test_norm_df = pd.DataFrame(data=X_test_norm.toarray())\n",
    "features_test = pd.concat([X_test_counter, X_test_norm_df], ignore_index=False, axis=1)\n",
    "features_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atlantic</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>19</td>\n",
       "      <td>126</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>117</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buzzfeed News</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox News</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guardian</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPR</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Review</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Post</th>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Times</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talking Points Memo</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vox</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Post</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0                0    1   2   3   4    5   6   7   8   9   10  11  12  13  \\\n",
       "publication                                                                     \n",
       "Atlantic              2   19   4   3  39   30   3   7   6   3   1   5  16   5   \n",
       "Breitbart            19  126  25  33  38  117  13  30  17  30  11  61  61   7   \n",
       "Business Insider      3   29   0   2  12   25   2   6   3   2  13  12   7   4   \n",
       "Buzzfeed News         1   11   0   7   4    9   6   4   8   1   5   5  11   2   \n",
       "CNN                   1   44   0  20  22   30  10  10   1  12   2   4  19   8   \n",
       "Fox News              4   17   1   9   2   15   3   3   2   6   0  17  10   2   \n",
       "Guardian              0   18   0   8  14    9   4   5   4   3   3   0  12   6   \n",
       "NPR                   4   25   4   3  21   18   9   3   6   8   3   8   9   4   \n",
       "National Review       5   10   4   3  16   21   1   7   1  10   0   6  10   2   \n",
       "New York Post         0   74  18  24  77   22  17   4  15   4  24   8  11   4   \n",
       "New York Times        0    7   2   1   5    3   1   1   0   5   2   1   5   3   \n",
       "Reuters               0    3  14   0   0    2   0   2   2   0   6   0   2   1   \n",
       "Talking Points Memo   6   24   3   4   8   23   2  26   4   4   0   7  12   7   \n",
       "Vox                   1   13   9   3  22   17   1   8   2   4   3   6   4   1   \n",
       "Washington Post       1   15   5  11  15   41   1  13   6   4   3  19  17   4   \n",
       "\n",
       "col_0                14  \n",
       "publication              \n",
       "Atlantic              9  \n",
       "Breitbart             8  \n",
       "Business Insider      3  \n",
       "Buzzfeed News         0  \n",
       "CNN                   6  \n",
       "Fox News              4  \n",
       "Guardian              1  \n",
       "NPR                  28  \n",
       "National Review       3  \n",
       "New York Post        19  \n",
       "New York Times        0  \n",
       "Reuters               0  \n",
       "Talking Points Memo   2  \n",
       "Vox                   1  \n",
       "Washington Post       1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calulate predicted values\n",
    "kmeans = KMeans(n_clusters=15, init='k-means++', random_state=42, n_init=20)\n",
    "y_pred_test = kmeans.fit_predict(features_test)\n",
    "\n",
    "pd.crosstab(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.02235029\n",
      "Silhouette Score: 0.07125383\n"
     ]
    }
   ],
   "source": [
    "print('Adjusted Rand Score: {:0.7}'.format(adjusted_rand_score(y_test, y_pred_test)))\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(features_test, y_pred_test, sample_size=60000, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test_c = pd.DataFrame(features_test)\n",
    "X2_test_c['kmeans_clust'] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.46748(+/- 0.033)\n"
     ]
    }
   ],
   "source": [
    "gbc_grid_scores_test = cross_val_score(gbc_grid, features_test, y_test, cv=5)\n",
    "print('Test set score: {:.5f}(+/- {:.3f})'.format(gbc_grid_scores_test.mean(), gbc_grid_scores_test.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "\n",
    "https://www.kaggle.com/snapcrack/all-the-news"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
