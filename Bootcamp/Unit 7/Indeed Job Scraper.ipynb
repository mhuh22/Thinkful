{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic summary of what this capstone will, and may accomplish\n",
    "\n",
    "* Scrape data from indeed, and return job postings\n",
    "* properly format location, title, requirements\n",
    "* analyze what words and requirements occur the most\n",
    "* Determine the quality of each job posting (how generic does it sound, and how common are the phrases that they are using) - this is important, but needs a bit of refinement\n",
    "\n",
    "Stretch goals\n",
    "* add input to allow users to specifiy the cities to look at\n",
    "\n",
    "* add a map to visualize how many postings there are in each city \n",
    "\n",
    "Current Issues\n",
    "* Sponsored job posts show up in data multiple times, and location data is missing\n",
    "* Summary page is not formated properly, .split() doesn't fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Job Scraper\n",
    "\n",
    "So far, it can scrape a job's\n",
    "\n",
    "* location\n",
    "* title\n",
    "* company name\n",
    "* salary\n",
    "* summary\n",
    "\n",
    "to-do\n",
    "\n",
    "* responsibilities\n",
    "* requirements\n",
    "\n",
    "not required, but would be nice\n",
    "\n",
    "* additional queries\n",
    "* additional cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 100\n",
    "#city_set = ['New+York','Chicago','San+Francisco', 'Austin', 'Seattle', 'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', 'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', 'Washington+DC', 'Boulder']\n",
    "# titles = ['data+analyst', 'business+analyst', 'data+scientist', 'machine+learning']\n",
    "city_set = ['New+York']\n",
    "columns = ['city', 'job_title', 'company_name', 'location', 'summary']\n",
    "sample_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(query,metro):\n",
    "    \n",
    "    url = \"https://www.indeed.com/jobs?q={}&l={}&start={}\"\n",
    "    n = 50\n",
    "    \n",
    "    # Create dataframe that we'll return later\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\", \"Query\", \"Metro\"])\n",
    "    \n",
    "    # Scrape first n pages\n",
    "    for i in range(0,n):\n",
    "        html = requests.get(url.format(query, metro, i))\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        \n",
    "        for each in soup.find_all(class_= \"result\" ):\n",
    "            try: \n",
    "                title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "            except:\n",
    "                title = 'None'\n",
    "            try:\n",
    "                location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "            except:\n",
    "                location = 'None'\n",
    "            try: \n",
    "                company = each.find(class_='company').text.replace('\\n', '')\n",
    "            except:\n",
    "                company = 'None'\n",
    "            try:\n",
    "                salary = each.find('span', {'class':'no-wrap'}).text\n",
    "            except:\n",
    "                salary = 'None'\n",
    "            synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "            df = df.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis, 'Query': query, 'Metro': metro}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the first URL\n",
    "data1 = parse('data+analyst', 'washington+dc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the second URL\n",
    "data2 = parse('data+scientist', 'washington+dc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the third URL\n",
    "data3 = parse('data+engineer', 'washington+dc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "data = pd.concat([data1,data2,data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scraped data to a local directory\n",
    "if os.path.exists(\"data/dc_indeed.csv\"):\n",
    "    os.remove(\"data/dc_indeed.csv\")\n",
    "data.to_csv('data/dc_indeed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Query</th>\n",
       "      <th>Metro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intelligence Analyst - Entry/Mid-Level</td>\n",
       "      <td>None</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>\\n                $45,972 - $73,105 a year</td>\n",
       "      <td>Entry is with a hi...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>Callahan &amp; Associates</td>\n",
       "      <td>None</td>\n",
       "      <td>Hands on experienc...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>Washington Metropolitan Area Transit A...</td>\n",
       "      <td>None</td>\n",
       "      <td>Data processing, data warehousing, and databas...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Product Modeling Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>GEICO</td>\n",
       "      <td>None</td>\n",
       "      <td>Statistical Modeli...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>Chenega Corporation</td>\n",
       "      <td>None</td>\n",
       "      <td>Perform data entry...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Health Interventions and Claims Data Analyst</td>\n",
       "      <td>Washington, DC 20007 (Georgetown area)</td>\n",
       "      <td>Innovation Center for Biomedical Infor...</td>\n",
       "      <td>None</td>\n",
       "      <td>We are working on applying data sc...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst 1 - Petroleum Supply</td>\n",
       "      <td>Washington, DC 20585</td>\n",
       "      <td>IMG Crown Energy Services Joint Venture</td>\n",
       "      <td>\\n                $40,000 - $45,000 a year</td>\n",
       "      <td>Supporting the data validation tea...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Fellowship (Spring 2018)</td>\n",
       "      <td>Alexandria, VA</td>\n",
       "      <td>Echelon Insights</td>\n",
       "      <td>\\n                $1,000 a month</td>\n",
       "      <td>Fellows with proven abilities in t...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MS Excel Data Analyst F32711</td>\n",
       "      <td>Washington, DC 20260 (South West area)</td>\n",
       "      <td>SyApps LLC</td>\n",
       "      <td>None</td>\n",
       "      <td>Analyzing all types of data sets. ...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst 1</td>\n",
       "      <td>Washington, DC 20585</td>\n",
       "      <td>IMG Crown Energy Services Joint Venture</td>\n",
       "      <td>\\n                $42,000 - $45,000 a year</td>\n",
       "      <td>Reviews data edits to ensure accur...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0        Intelligence Analyst - Entry/Mid-Level   \n",
       "1                                  Data Analyst   \n",
       "2                 Business Intelligence Analyst   \n",
       "3                      Product Modeling Analyst   \n",
       "4                                  Data Analyst   \n",
       "5  Health Interventions and Claims Data Analyst   \n",
       "6             Data Analyst 1 - Petroleum Supply   \n",
       "7                 Data Fellowship (Spring 2018)   \n",
       "8                  MS Excel Data Analyst F32711   \n",
       "9                                Data Analyst 1   \n",
       "\n",
       "                                 Location  \\\n",
       "0                                    None   \n",
       "1                                    None   \n",
       "2                                    None   \n",
       "3                                    None   \n",
       "4                                    None   \n",
       "5  Washington, DC 20007 (Georgetown area)   \n",
       "6                    Washington, DC 20585   \n",
       "7                          Alexandria, VA   \n",
       "8  Washington, DC 20260 (South West area)   \n",
       "9                    Washington, DC 20585   \n",
       "\n",
       "                                             Company  \\\n",
       "0                           National Security Agency   \n",
       "1                              Callahan & Associates   \n",
       "2          Washington Metropolitan Area Transit A...   \n",
       "3                                              GEICO   \n",
       "4                                Chenega Corporation   \n",
       "5          Innovation Center for Biomedical Infor...   \n",
       "6            IMG Crown Energy Services Joint Venture   \n",
       "7                                   Echelon Insights   \n",
       "8                                         SyApps LLC   \n",
       "9            IMG Crown Energy Services Joint Venture   \n",
       "\n",
       "                                       Salary  \\\n",
       "0  \\n                $45,972 - $73,105 a year   \n",
       "1                                        None   \n",
       "2                                        None   \n",
       "3                                        None   \n",
       "4                                        None   \n",
       "5                                        None   \n",
       "6  \\n                $40,000 - $45,000 a year   \n",
       "7            \\n                $1,000 a month   \n",
       "8                                        None   \n",
       "9  \\n                $42,000 - $45,000 a year   \n",
       "\n",
       "                                            Synopsis         Query  \\\n",
       "0                              Entry is with a hi...  data+analyst   \n",
       "1                              Hands on experienc...  data+analyst   \n",
       "2  Data processing, data warehousing, and databas...  data+analyst   \n",
       "3                              Statistical Modeli...  data+analyst   \n",
       "4                              Perform data entry...  data+analyst   \n",
       "5              We are working on applying data sc...  data+analyst   \n",
       "6              Supporting the data validation tea...  data+analyst   \n",
       "7              Fellows with proven abilities in t...  data+analyst   \n",
       "8              Analyzing all types of data sets. ...  data+analyst   \n",
       "9              Reviews data edits to ensure accur...  data+analyst   \n",
       "\n",
       "           Metro  \n",
       "0  washington+dc  \n",
       "1  washington+dc  \n",
       "2  washington+dc  \n",
       "3  washington+dc  \n",
       "4  washington+dc  \n",
       "5  washington+dc  \n",
       "6  washington+dc  \n",
       "7  washington+dc  \n",
       "8  washington+dc  \n",
       "9  washington+dc  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
