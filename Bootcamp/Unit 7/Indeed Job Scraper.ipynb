{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic summary of what this capstone will, and may accomplish\n",
    "\n",
    "* Scrape data from indeed, and return job postings\n",
    "* properly format location, title, requirements\n",
    "* analyze what words and requirements occur the most\n",
    "* Determine the quality of each job posting (how generic does it sound, and how common are the phrases that they are using) - this is important, but needs a bit of refinement\n",
    "\n",
    "Stretch goals\n",
    "* add input to allow users to specifiy the cities to look at\n",
    "\n",
    "* add a map to visualize how many postings there are in each city \n",
    "\n",
    "Current Issues\n",
    "* Sponsored job posts show up in data multiple times, and location data is missing\n",
    "* Summary page is not formated properly, .split() doesn't fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Job Scraper\n",
    "\n",
    "So far, it can scrape a job's\n",
    "\n",
    "* location\n",
    "* title\n",
    "* company name\n",
    "* salary\n",
    "* summary\n",
    "\n",
    "to-do\n",
    "\n",
    "* responsibilities\n",
    "* requirements\n",
    "\n",
    "not required, but would be nice\n",
    "\n",
    "* additional queries\n",
    "* additional cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 100\n",
    "#city_set = ['New+York','Chicago','San+Francisco', 'Austin', 'Seattle', 'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', 'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', 'Washington+DC', 'Boulder']\n",
    "# titles = ['data+analyst', 'business+analyst', 'data+scientist', 'machine+learning']\n",
    "city_set = ['New+York']\n",
    "columns = ['city', 'job_title', 'company_name', 'location', 'summary']\n",
    "sample_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(query,metro):\n",
    "    \n",
    "    # Target url, and n number of pages to scrape\n",
    "    url = \"https://www.indeed.com/jobs?q={}&l={}&start={}\"\n",
    "    n = 30\n",
    "    \n",
    "    # Create dataframe that we'll return later\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\", \"Query\", \"Metro\"])\n",
    "    \n",
    "    # Scrape first n pages\n",
    "    for i in range(0,n):\n",
    "        html = requests.get(url.format(query, metro, i))\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        \n",
    "        for each in soup.find_all(class_= \"result\" ):\n",
    "            try: \n",
    "                title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "            except:\n",
    "                title = 'None'\n",
    "            try:\n",
    "                location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "            except:    \n",
    "                try:\n",
    "                    location = each.find('div', {'class':\"location\" }).text.replace('\\n', '')\n",
    "                except:\n",
    "                    location = 'None'\n",
    "            try: \n",
    "                company = each.find(class_='company').text.replace('\\n', '')\n",
    "            except:\n",
    "                company = 'None'\n",
    "            try:\n",
    "                salary = each.find('span', {'class':'no-wrap'}).text\n",
    "            except:\n",
    "                salary = 'None'\n",
    "            synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "            df = df.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis, 'Query': query, 'Metro': metro}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of positions and locations to search\n",
    "positions = ['data+analyst', 'data+scientist', 'data+engineer']\n",
    "cities = ['washington+dc']\n",
    "\n",
    "# Create the dataframe\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Scrape all positions in all cities specified, and append to dataframe\n",
    "for position in positions:\n",
    "    for city in cities:\n",
    "        data = pd.concat([data, parse(position, city)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scraped data to a local directory\n",
    "if os.path.exists(\"data/dc_indeed.csv\"):\n",
    "    os.remove(\"data/dc_indeed.csv\")\n",
    "data.to_csv('data/dc_indeed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Query</th>\n",
       "      <th>Metro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Chenega Corporation</td>\n",
       "      <td>None</td>\n",
       "      <td>Perform data entry...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Program Data Analyst</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>RGS</td>\n",
       "      <td>None</td>\n",
       "      <td>Organize and build...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Human Capital Analytics</td>\n",
       "      <td>Bethesda, MD 20816</td>\n",
       "      <td>Leidos</td>\n",
       "      <td>None</td>\n",
       "      <td>Review, assess dat...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intelligence Analyst with TS/SCI</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Object CTalk Inc.</td>\n",
       "      <td>None</td>\n",
       "      <td>Strong analytical ...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Systems Analyst/Data Scientist</td>\n",
       "      <td>Springfield, VA</td>\n",
       "      <td>Radiant Solutions</td>\n",
       "      <td>None</td>\n",
       "      <td>We build advanced ...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aviation Data Systems Analyst</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Concepts Beyond</td>\n",
       "      <td>None</td>\n",
       "      <td>The Analyst will p...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Health Interventions and Claims Data Analyst</td>\n",
       "      <td>Washington, DC 20007 (Georgetown area)</td>\n",
       "      <td>Innovation Center for Biomedical Infor...</td>\n",
       "      <td>None</td>\n",
       "      <td>We are working on applying data sc...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Political Data Service Analyst</td>\n",
       "      <td>Washington, DC 20005 (Logan Circle area)</td>\n",
       "      <td>Data Trust</td>\n",
       "      <td>None</td>\n",
       "      <td>The Data Services Analyst will be ...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Part Time/Full Time Administrative Assistant</td>\n",
       "      <td>Washington, DC 20003 (Capitol Hill area)</td>\n",
       "      <td>General Dynamics Information Technology</td>\n",
       "      <td>\\n                $16 - $18 an hour</td>\n",
       "      <td>Support Program + Management analy...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Contractual Data Analyst (STASI)</td>\n",
       "      <td>Washington, DC 20431 (Foggy Bottom area)</td>\n",
       "      <td>International Monetary Fund</td>\n",
       "      <td>None</td>\n",
       "      <td>Contractual Data Analyst (STASI) (...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0                                  Data Analyst   \n",
       "1                          Program Data Analyst   \n",
       "2      Data Scientist - Human Capital Analytics   \n",
       "3              Intelligence Analyst with TS/SCI   \n",
       "4                Systems Analyst/Data Scientist   \n",
       "5                 Aviation Data Systems Analyst   \n",
       "6  Health Interventions and Claims Data Analyst   \n",
       "7                Political Data Service Analyst   \n",
       "8  Part Time/Full Time Administrative Assistant   \n",
       "9              Contractual Data Analyst (STASI)   \n",
       "\n",
       "                                   Location  \\\n",
       "0                            Washington, DC   \n",
       "1                             Arlington, VA   \n",
       "2                        Bethesda, MD 20816   \n",
       "3                            Washington, DC   \n",
       "4                           Springfield, VA   \n",
       "5                            Washington, DC   \n",
       "6    Washington, DC 20007 (Georgetown area)   \n",
       "7  Washington, DC 20005 (Logan Circle area)   \n",
       "8  Washington, DC 20003 (Capitol Hill area)   \n",
       "9  Washington, DC 20431 (Foggy Bottom area)   \n",
       "\n",
       "                                             Company  \\\n",
       "0                                Chenega Corporation   \n",
       "1                                                RGS   \n",
       "2                                             Leidos   \n",
       "3                                  Object CTalk Inc.   \n",
       "4                                  Radiant Solutions   \n",
       "5                                    Concepts Beyond   \n",
       "6          Innovation Center for Biomedical Infor...   \n",
       "7                                         Data Trust   \n",
       "8            General Dynamics Information Technology   \n",
       "9                        International Monetary Fund   \n",
       "\n",
       "                                Salary  \\\n",
       "0                                 None   \n",
       "1                                 None   \n",
       "2                                 None   \n",
       "3                                 None   \n",
       "4                                 None   \n",
       "5                                 None   \n",
       "6                                 None   \n",
       "7                                 None   \n",
       "8  \\n                $16 - $18 an hour   \n",
       "9                                 None   \n",
       "\n",
       "                                            Synopsis         Query  \\\n",
       "0                              Perform data entry...  data+analyst   \n",
       "1                              Organize and build...  data+analyst   \n",
       "2                              Review, assess dat...  data+analyst   \n",
       "3                              Strong analytical ...  data+analyst   \n",
       "4                              We build advanced ...  data+analyst   \n",
       "5                              The Analyst will p...  data+analyst   \n",
       "6              We are working on applying data sc...  data+analyst   \n",
       "7              The Data Services Analyst will be ...  data+analyst   \n",
       "8              Support Program + Management analy...  data+analyst   \n",
       "9              Contractual Data Analyst (STASI) (...  data+analyst   \n",
       "\n",
       "           Metro  \n",
       "0  washington+dc  \n",
       "1  washington+dc  \n",
       "2  washington+dc  \n",
       "3  washington+dc  \n",
       "4  washington+dc  \n",
       "5  washington+dc  \n",
       "6  washington+dc  \n",
       "7  washington+dc  \n",
       "8  washington+dc  \n",
       "9  washington+dc  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1485, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return size of dataframe\n",
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
