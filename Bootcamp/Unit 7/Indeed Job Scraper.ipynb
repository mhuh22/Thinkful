{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic summary of what this capstone will, and may accomplish\n",
    "\n",
    "* Scrape data from indeed, and return job postings\n",
    "* properly format location, title, requirements\n",
    "* analyze what words and requirements occur the most\n",
    "* Determine the quality of each job posting (how generic does it sound, and how common are the phrases that they are using) - this is important, but needs a bit of refinement\n",
    "\n",
    "Stretch goals\n",
    "* add input to allow users to specifiy the cities to look at\n",
    "\n",
    "* add a map to visualize how many postings there are in each city \n",
    "\n",
    "Current Issues\n",
    "* Sponsored job posts show up in data multiple times, and location data is missing\n",
    "* Summary page is not formated properly, .split() doesn't fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Job Scraper\n",
    "\n",
    "So far, it can scrape a job's\n",
    "\n",
    "* location\n",
    "* title\n",
    "* company name\n",
    "* salary\n",
    "* summary\n",
    "* (html - data is unstructured, though)\n",
    "\n",
    "would be nice, but idk how to implement\n",
    "\n",
    "* responsibilities\n",
    "* requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(query,metro):\n",
    "    \n",
    "    # Target url, and n number of pages to scrape\n",
    "    url = \"https://www.indeed.com/jobs?q={}&l={}&start={}\"\n",
    "    n = 10\n",
    "    \n",
    "    # Create dataframe that we'll return later\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\", \"Query\", \"Metro\"])\n",
    "    \n",
    "    # Scrape first n pages\n",
    "    for i in range(0,n):\n",
    "        html = requests.get(url.format(query, metro, i))\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        \n",
    "        for each in soup.find_all(class_= \"result\" ):\n",
    "            try: \n",
    "                title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "            except:\n",
    "                title = 'None'\n",
    "            try:\n",
    "                location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "            except:    \n",
    "                try:\n",
    "                    location = each.find('div', {'class':\"location\" }).text.replace('\\n', '')\n",
    "                except:\n",
    "                    location = 'None'\n",
    "            try: \n",
    "                company = each.find(class_='company').text.replace('\\n', '')\n",
    "            except:\n",
    "                company = 'None'\n",
    "            try:\n",
    "                salary = each.find('span', {'class':'no-wrap'}).text\n",
    "            except:\n",
    "                salary = 'None'\n",
    "            try:\n",
    "                link = 'https://www.indeed.com/viewjob' + each.find('a', href=True)['href'][7:]\n",
    "            except:    \n",
    "                link = 'None'\n",
    "            synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "            df = df.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis, 'Query': query, 'Metro': metro}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of positions and locations to search\n",
    "positions = ['data+analyst', 'data+scientist', 'data+engineer']\n",
    "cities = ['washington+dc']\n",
    "\n",
    "# Create the dataframe\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Scrape all positions in all cities specified, and append to dataframe\n",
    "for position in positions:\n",
    "    for city in cities:\n",
    "        data = pd.concat([data, parse(position, city)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scraped data to a local directory\n",
    "if os.path.exists(\"data/dc_indeed.csv\"):\n",
    "    os.remove(\"data/dc_indeed.csv\")\n",
    "data.to_csv('data/dc_indeed.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Query</th>\n",
       "      <th>Metro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Chenega Corporation</td>\n",
       "      <td>None</td>\n",
       "      <td>Perform data entry...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Callahan &amp; Associates</td>\n",
       "      <td>None</td>\n",
       "      <td>Hands on experienc...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Modeling Analyst</td>\n",
       "      <td>Chevy Chase, MD</td>\n",
       "      <td>GEICO</td>\n",
       "      <td>None</td>\n",
       "      <td>Statistical Modeli...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Human Capital Analytics</td>\n",
       "      <td>Bethesda, MD 20816</td>\n",
       "      <td>Leidos</td>\n",
       "      <td>None</td>\n",
       "      <td>Review, assess dat...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Systems Analyst/Data Scientist</td>\n",
       "      <td>Springfield, VA</td>\n",
       "      <td>Radiant Solutions</td>\n",
       "      <td>None</td>\n",
       "      <td>We build advanced ...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>Common Securitization Solutions</td>\n",
       "      <td>None</td>\n",
       "      <td>Ability to determi...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Health Interventions and Claims Data Analyst</td>\n",
       "      <td>Washington, DC 20007 (Georgetown area)</td>\n",
       "      <td>Innovation Center for Biomedical Infor...</td>\n",
       "      <td>None</td>\n",
       "      <td>We are working on applying data sc...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst 1 - Petroleum Supply</td>\n",
       "      <td>Washington, DC 20585</td>\n",
       "      <td>IMG Crown Energy Services Joint Venture</td>\n",
       "      <td>\\n                $40,000 - $45,000 a year</td>\n",
       "      <td>Supporting the data validation tea...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Fellowship (Spring 2018)</td>\n",
       "      <td>Alexandria, VA</td>\n",
       "      <td>Echelon Insights</td>\n",
       "      <td>\\n                $1,000 a month</td>\n",
       "      <td>Fellows with proven abilities in t...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Political Data Analyst - Outside Groups</td>\n",
       "      <td>Washington, DC 20005 (Logan Circle area)</td>\n",
       "      <td>Data Trust</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Trust is currently seeking a Data Analyst...</td>\n",
       "      <td>data+analyst</td>\n",
       "      <td>washington+dc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0                                  Data Analyst   \n",
       "1                                  Data Analyst   \n",
       "2                      Product Modeling Analyst   \n",
       "3      Data Scientist - Human Capital Analytics   \n",
       "4                Systems Analyst/Data Scientist   \n",
       "5                 Business Intelligence Analyst   \n",
       "6  Health Interventions and Claims Data Analyst   \n",
       "7             Data Analyst 1 - Petroleum Supply   \n",
       "8                 Data Fellowship (Spring 2018)   \n",
       "9       Political Data Analyst - Outside Groups   \n",
       "\n",
       "                                   Location  \\\n",
       "0                            Washington, DC   \n",
       "1                            Washington, DC   \n",
       "2                           Chevy Chase, MD   \n",
       "3                        Bethesda, MD 20816   \n",
       "4                           Springfield, VA   \n",
       "5                              Bethesda, MD   \n",
       "6    Washington, DC 20007 (Georgetown area)   \n",
       "7                      Washington, DC 20585   \n",
       "8                            Alexandria, VA   \n",
       "9  Washington, DC 20005 (Logan Circle area)   \n",
       "\n",
       "                                             Company  \\\n",
       "0                                Chenega Corporation   \n",
       "1                              Callahan & Associates   \n",
       "2                                              GEICO   \n",
       "3                                             Leidos   \n",
       "4                                  Radiant Solutions   \n",
       "5                    Common Securitization Solutions   \n",
       "6          Innovation Center for Biomedical Infor...   \n",
       "7            IMG Crown Energy Services Joint Venture   \n",
       "8                                   Echelon Insights   \n",
       "9                                         Data Trust   \n",
       "\n",
       "                                       Salary  \\\n",
       "0                                        None   \n",
       "1                                        None   \n",
       "2                                        None   \n",
       "3                                        None   \n",
       "4                                        None   \n",
       "5                                        None   \n",
       "6                                        None   \n",
       "7  \\n                $40,000 - $45,000 a year   \n",
       "8            \\n                $1,000 a month   \n",
       "9                                        None   \n",
       "\n",
       "                                            Synopsis         Query  \\\n",
       "0                              Perform data entry...  data+analyst   \n",
       "1                              Hands on experienc...  data+analyst   \n",
       "2                              Statistical Modeli...  data+analyst   \n",
       "3                              Review, assess dat...  data+analyst   \n",
       "4                              We build advanced ...  data+analyst   \n",
       "5                              Ability to determi...  data+analyst   \n",
       "6              We are working on applying data sc...  data+analyst   \n",
       "7              Supporting the data validation tea...  data+analyst   \n",
       "8              Fellows with proven abilities in t...  data+analyst   \n",
       "9  Data Trust is currently seeking a Data Analyst...  data+analyst   \n",
       "\n",
       "           Metro  \n",
       "0  washington+dc  \n",
       "1  washington+dc  \n",
       "2  washington+dc  \n",
       "3  washington+dc  \n",
       "4  washington+dc  \n",
       "5  washington+dc  \n",
       "6  washington+dc  \n",
       "7  washington+dc  \n",
       "8  washington+dc  \n",
       "9  washington+dc  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return size of dataframe\n",
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
