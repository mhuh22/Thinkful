{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the Data\n",
    "\n",
    "The dataset for this challenge has been obtained from the European Social Survey. Our objective for this challenge is to determine what variables we can use to predict if a person has a partner or not, and how significant each variable is for predicting the outcome.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "From our initial decision tree, we were able to predict whether someone has a partner or not with an error rate of 6.258% for false positives, and 18.528% for false negatives. The challenge here is to reduce those error rates through modifying the features and the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def booster (X, y, iterations, loss, depth):\n",
    "    # Create training and test sets.\n",
    "    offset = int(X.shape[0] * 0.8)\n",
    "\n",
    "    # Put 90% of the data in the training set.\n",
    "    X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "    # And put 10% in the test set.\n",
    "    X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "    # We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "    params = {'n_estimators': iterations,\n",
    "              'max_depth': depth,\n",
    "              'loss': loss}\n",
    "\n",
    "    # Initialize and fit the model.\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "\n",
    "    # Accuracy tables.\n",
    "    table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "    table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "    train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "    train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "    test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "    test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "    print((\n",
    "        'Training set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}\\n\\n'\n",
    "        'Test set accuracy:\\n'\n",
    "        'Percent Type I errors: {}\\n'\n",
    "        'Percent Type II errors: {}'\n",
    "    ).format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04603345097437471\n",
      "Percent Type II errors: 0.1752340033757864\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09693251533742331\n",
      "Percent Type II errors: 0.1558282208588957\n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X1 = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X1 = pd.concat([X1, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "booster(X1, y, 500, 'deviance', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0469541199938622\n",
      "Percent Type II errors: 0.17784256559766765\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.10429447852760736\n",
      "Percent Type II errors: 0.15521472392638036\n"
     ]
    }
   ],
   "source": [
    "# Changed loss type - less accurate\n",
    "booster(X1, y, 500, 'exponential', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04342488875249348\n",
      "Percent Type II errors: 0.1677152063833052\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08282208588957055\n",
      "Percent Type II errors: 0.17484662576687116\n"
     ]
    }
   ],
   "source": [
    "# Doubled number of iterations + more accurate\n",
    "booster(X1, y, 1000, 'deviance', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03206997084548105\n",
      "Percent Type II errors: 0.1310418904403867\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.04171779141104295\n",
      "Percent Type II errors: 0.22576687116564417\n"
     ]
    }
   ],
   "source": [
    "# Significantly higher number of iterations + more accurate\n",
    "booster(X1, y, 10000, 'deviance', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.016572042350774897\n",
      "Percent Type II errors: 0.11124750652140555\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09263803680981596\n",
      "Percent Type II errors: 0.1588957055214724\n"
     ]
    }
   ],
   "source": [
    "# Doubled tree depth + more accurate\n",
    "booster(X1, y, 500, 'deviance', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X1 ** 2\n",
    "X3 = np.sqrt(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04603345097437471\n",
      "Percent Type II errors: 0.1752340033757864\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09693251533742331\n",
      "Percent Type II errors: 0.1558282208588957\n"
     ]
    }
   ],
   "source": [
    "booster(X1 + X2, y, 500, 'deviance', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04603345097437471\n",
      "Percent Type II errors: 0.1752340033757864\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09693251533742331\n",
      "Percent Type II errors: 0.1558282208588957\n"
     ]
    }
   ],
   "source": [
    "booster(X3, y, 500, 'deviance', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04603345097437471\n",
      "Percent Type II errors: 0.1752340033757864\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09693251533742331\n",
      "Percent Type II errors: 0.1558282208588957\n"
     ]
    }
   ],
   "source": [
    "booster(X1, y, 500, 'deviance', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
