{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests\n",
    "\n",
    "Requests are built-in to python, and extracts raw HTML. It also has the potential to be used with APIs, post to forms, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in requests\n",
    "\n",
    "import requests\n",
    "page = requests.get('https://scrapy.org/')\n",
    "contents = page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n\\n  <head>\\n    <meta charset=\"utf-8\">\\n\\n    <title>Scrapy | A Fast and Powerful Scraping and Web Crawling Framework</title>\\n    <meta name=\"description\" content=\"\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"57x57\" href=\"/favicons/apple-touch-icon-57x57.png\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"114x114\" href=\"/favicons/apple-touch-icon-114x114.png\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"72x72\" href=\"/favicons/apple-touch-icon-72x72.png\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"144x144\" href=\"/favicons/apple-touch-icon-144x144.png\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"60x60\" href=\"/favicons/apple-touch-icon-60x60.png\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"120x120\" href=\"/favicons/apple-touch-icon-120x120.png\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"76x76\" href=\"/favicons/apple-touch-icon-76x76.png\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"152x152\" href=\"/favicons/apple-touch-icon-152x152.png\">\\n\\t<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/favicons/apple-touch-icon-180x180.png\">\\n\\t<link rel=\"icon\" type=\"image/png\" href=\"/favicons/favicon-192x192.png\" sizes=\"192x192\">\\n\\t<link rel=\"icon\" type=\"image/png\" href=\"/favicons/favicon-160x160.png\" sizes=\"160x160\">\\n\\t<link rel=\"icon\" type=\"image/png\" href=\"/favicons/favicon-96x96.png\" sizes=\"96x96\">\\n\\t<link rel=\"icon\" type=\"image/png\" href=\"/favicons/favicon-16x16.png\" sizes=\"16x16\">\\n\\t<link rel=\"icon\" type=\"image/png\" href=\"/favicons/favicon-32x32.png\" sizes=\"32x32\">\\n\\t<meta name=\"msapplication-TileColor\" content=\"#da532c\">\\n\\t<meta name=\"msapplication-TileImage\" content=\"/favicons/mstile-144x144.png\">\\n    \\n    <link rel=\"stylesheet\" href=\"/css/main.css\">\\n    <link rel=\"stylesheet\" href=\"/css/font-awesome.min.css\">\\n\\n    <link href=\\'https://fonts.googleapis.com/css?family=Bitter:400,700,400italic\\' rel=\\'stylesheet\\' type=\\'text/css\\'>\\n\\t<link href=\\'https://fonts.googleapis.com/css?family=Ubuntu+Mono\\' rel=\\'stylesheet\\' type=\\'text/css\\'>\\n    <link href=\\'https://fonts.googleapis.com/css?family=Ubuntu\\' rel=\\'stylesheet\\' type=\\'text/css\\'>\\n    <link href=\\'https://fonts.googleapis.com/css?family=Bitter\\' rel=\\'stylesheet\\' type=\\'text/css\\'>\\n\\t<script>\\n(function(i,s,o,g,r,a,m){i[\\'GoogleAnalyticsObject\\']=r;i[r]=i[r]||function(){\\n(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\\nm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\\n})(window,document,\\'script\\',\\'https://www.google-analytics.com/analytics.js\\',\\'gaScrapy\\');\\n\\ngaScrapy(\\'create\\', \\'UA-10231918-1\\', \\'auto\\');\\ngaScrapy(\\'send\\', \\'pageview\\');\\n</script>\\n\\n<script type=\"text/javascript\">\\n!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error(\"Segment snippet included twice.\");else{analytics.invoked=!0;analytics.methods=[\"trackSubmit\",\"trackClick\",\"trackLink\",\"trackForm\",\"pageview\",\"identify\",\"reset\",\"group\",\"track\",\"ready\",\"alias\",\"page\",\"once\",\"off\",\"on\"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement(\"script\");e.type=\"text/javascript\";e.async=!0;e.src=(\"https:\"===document.location.protocol?\"https://\":\"http://\")+\"cdn.segment.com/analytics.js/v1/\"+t+\"/analytics.min.js\";var n=document.getElementsByTagName(\"script\")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION=\"3.1.0\";\\nanalytics.load(\"8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA\");\\nanalytics.page();\\n}}();\\n\\nanalytics.ready(function () {\\n    ga(\\'require\\', \\'linker\\');\\n    ga(\\'linker:autoLink\\', [\\'scrapinghub.com\\', \\'crawlera.com\\']);\\n});\\n</script>\\n\\n    <meta name=\"google-site-verification\" content=\"yxZDsO9N9GjO2Bf5VnB6WlCJyg4-TH6NDIDQgxLv1f4\" />\\n    \\n</head>\\n\\n\\n  <body>\\n\\n    <div class=\"header\">\\n\\n<div class=\"container\">\\n\\n  <a href=\"https://scrapy.org\" id=\"link-logo\"><div class=\"logo\"></div></a>\\n\\n\\n\\n  \\n    <ul class=\"navigation\">\\n      \\n        \\n        \\n\\n        <a class=\"\" href=\"../download/\" id=\"link-download\">\\n          <li class=\"first  \">\\n            Download\\n          </li>\\n        </a>\\n      \\n        \\n        \\n\\n        <a class=\"\" href=\"../doc/\" id=\"link-documentation\">\\n          <li class=\"  \">\\n            Documentation\\n          </li>\\n        </a>\\n      \\n        \\n        \\n\\n        <a class=\"\" href=\"../resources/\" id=\"link-resources\">\\n          <li class=\"  \">\\n            Resources\\n          </li>\\n        </a>\\n      \\n        \\n        \\n\\n        <a class=\"\" href=\"../community/\" id=\"link-community\">\\n          <li class=\"  \">\\n            Community\\n          </li>\\n        </a>\\n      \\n        \\n        \\n\\n        <a class=\"\" href=\"../companies/\" id=\"link-commercial-support\">\\n          <li class=\"  last\">\\n            Commercial Support\\n          </li>\\n        </a>\\n      \\n      <a href=\"http://doc.scrapy.org/en/latest/faq.html\" id=\"link-faq\"><li>FAQ</li></a>\\n      <a href=\"https://github.com/scrapy/scrapy\" id=\"link-github\">\\n      <li><i class=\"fa fa-code-fork fa-lg\"></i> <span class=\"github-text\">Fork on Github</span></li>\\n      </a>\\n    </ul>\\n  \\n\\n</div>\\n\\n</div>\\n\\n\\n    <div class=\"page-content\">\\n      <div class=\"wrapper\">\\n        \\n\\n\\n\\n<div class=\"container\">\\n\\n  <div class=\"first-row\">\\n\\n    <div class=\"block-left\">\\n      <div id=\"scrapy-logo\"></div>\\n      <p>An open source and collaborative framework for extracting the data you need from websites.\\n      </p>\\n      <p>In a fast, simple, yet extensible way.</p>\\n\\n    <div class=\"badges-bar\">\\n  <a href=\"https://pypi.python.org/pypi/Scrapy\">\\n    <img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/Scrapy.svg\" style=\"max-width:100%;\">\\n  </a>\\n  <a href=\"https://pypi.python.org/pypi/Scrapy\">\\n    <img alt=\"Wheel Status\" src=\"https://img.shields.io/badge/wheel-yes-brightgreen.svg\" style=\"max-width:100%;\">\\n  </a>\\n  <a href=\"https://codecov.io/github/scrapy/scrapy?branch=master\">\\n    <img alt=\"Coverage report\" src=\"https://img.shields.io/codecov/c/github/scrapy/scrapy/master.svg\" style=\"max-width:100%;\">\\n  </a>\\n</div>\\n\\n    </div>\\n\\n    <div class=\"block-right\">\\n      <div class=\"big-button\">\\n  <div class=\"box-title\">Install the latest version of Scrapy</div>\\n  <div class=\"download-stripe\">\\n    <p> <i class=\"fa fa-cloud-download \"></i> Scrapy 1.5 </p>\\n  </div>\\n  <div class=\"install-code\"><span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> <span class=\"command\">pip install scrapy</span></div>\\n  <div class=\"download-alternatives\">\\n    <a href=\"http://pypi.python.org/pypi/Scrapy\"><button>PyPI</button></a>\\n    <a href=\"https://anaconda.org/conda-forge/scrapy\"><button>Conda</button></a>\\n  </div>\\n</div>\\n\\n    </div>\\n\\n  </div>\\n</div>\\n\\n<div class=\"second-row\">\\n  <div class=\"container code-box-line\">\\n    <div class=\"code-box\">\\n      <div class=\"box-header\">\\n        <p>Terminal<span class=\"close-btn\">&bull;</span></p>\\n      </div>\\n      <div class=\"box-code tab-page active-page\">\\n        <pre>\\n<span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> pip install scrapy\\n<span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> cat > myspider.py &lt;&lt;EOF\\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"kn\">import</span> <span class=\"nn\">scrapy</span>\\n\\n<span class=\"k\">class</span> <span class=\"nc\">BlogSpider</span><span class=\"p\">(</span><span class=\"n\">scrapy</span><span class=\"o\">.</span><span class=\"n\">Spider</span><span class=\"p\">):</span>\\n    <span class=\"n\">name</span> <span class=\"o\">=</span> <span class=\"s\">\\'blogspider\\'</span>\\n    <span class=\"n\">start_urls</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"s\">\\'https://blog.scrapinghub.com\\'</span><span class=\"p\">]</span>\\n\\n    <span class=\"k\">def</span> <span class=\"nf\">parse</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">response</span><span class=\"p\">):</span>\\n        <span class=\"k\">for</span> <span class=\"n\">title</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s\">\\'.post-header&gt;h2\\'</span><span class=\"p\">):</span>\\n            <span class=\"k\">yield</span> <span class=\"p\">{</span><span class=\"s\">\\'title\\'</span><span class=\"p\">:</span> <span class=\"n\">title</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s\">\\'a ::text\\'</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">extract_first</span><span class=\"p\">()}</span>\\n\\n        <span class=\"k\">for</span> <span class=\"n\">next_page</span> <span class=\"ow\">in</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">css</span><span class=\"p\">(</span><span class=\"s\">\\'div.prev-post &gt; a\\'</span><span class=\"p\">):</span>\\n            <span class=\"k\">yield</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">follow</span><span class=\"p\">(</span><span class=\"n\">next_page</span><span class=\"p\">,</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">parse</span><span class=\"p\">)</span></code></pre></figure>EOF\\n<span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> scrapy runspider myspider.py\\n</pre>\\n      </div>\\n    </div>\\n\\n    <div class=\"code-subs\"><p>Build and run your<br /><span class=\"highlight\">web spiders</span></p></div>\\n\\n  </div>\\n\\n  <div class=\"container code-box-line\">\\n    <div class=\"code-box\">\\n      <div class=\"box-header\">\\n        <p>Terminal<span class=\"close-btn\">&bull;</span></p>\\n      </div>\\n      <div class=\"box-code tab-page active-page\">\\n        <pre>\\n<span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> pip install shub\\n<span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> shub login\\n<span class=\"comments\">Insert your Scrapinghub API Key: <span class=\"placeholder\">&lt;API_KEY&gt;</span></span>\\n\\n<span class=\"comments\"># Deploy the spider to Scrapy Cloud</span>\\n<span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> shub deploy</span>\\n\\n<span class=\"comments\"># Schedule the spider for execution</span>\\n<span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> shub schedule blogspider <span class=\"comments\">\\nSpider blogspider scheduled, watch it running here:\\nhttps://app.scrapinghub.com/p/26731/job/1/8</span>\\n\\n<span class=\"comments\"># Retrieve the scraped data</span>\\n<span class=\"prompt\" onselectstart=\"return false\"><i class=\"fa fa-dollar\"></i></span> shub items 26731/1/8\\n<figure class=\"highlight\"><pre><code class=\"language-python\" data-lang=\"python\"><span class=\"p\">{</span><span class=\"s\">\"title\"</span><span class=\"p\">:</span> <span class=\"s\">\"Improved Frontera: Web Crawling at Scale with Python 3 Support\"</span><span class=\"p\">}</span>\\n<span class=\"p\">{</span><span class=\"s\">\"title\"</span><span class=\"p\">:</span> <span class=\"s\">\"How to Crawl the Web Politely with Scrapy\"</span><span class=\"p\">}</span>\\n<span class=\"o\">...</span></code></pre></figure></pre>\\n      </div>\\n    </div>\\n\\n    <div class=\"code-subs\"><p>Deploy them to<br /><a href=\"https://scrapinghub.com/scrapy-cloud/\" title=\"\"><span class=\"highlight\">Scrapy Cloud</span></a></p>\\n    <p class=\"sub-sub\">or use <a href=\"https://github.com/scrapy/scrapyd\" title=\"Scrapyd\"><span class=\"highlight\">Scrapyd</span></a> to host the spiders on your own server</p></div>\\n  </div>\\n\\n</div>\\n\\n<div class=\"container\">\\n\\n  <div class=\"third-row\">\\n    <div class=\"block-01\">\\n      <i class=\"fa fa-flash fa-4x\"> </i>\\n      <h3>Fast and powerful</h3>\\n      <p>write the rules to extract the data and let Scrapy do the rest</p>\\n    </div>\\n    <div class=\"block-02\">\\n      <i class=\"fa fa-puzzle-piece fa-4x\"> </i>\\n      <h3>Easily extensible</h3>\\n      <p>extensible by design, plug new functionality easily without having to touch the core</p>\\n    </div>\\n    <div class=\"block-03\">\\n      <i class=\"fa fa-cubes fa-4x\"> </i>\\n      <h3>Portable, Python</h3>\\n      <p>written in Python and runs on Linux, Windows, Mac and BSD</p>\\n    </div>\\n  </div>\\n</div>\\n\\n<div class=\\'fourth-row\\'>\\n  <div class=\"container\">\\n    <div class=\"block-left\">\\n      <h2>Healthy community</h2>\\n      <ul>\\n        <li>- 24k stars, 6k forks and 1.6k watchers on <a href=\"https://github.com/scrapy/scrapy\">GitHub</a></li>\\n        <li>- 4.0k followers on <a href=\"https://twitter.com/ScrapyProject\">Twitter</a></li>\\n        <li>- 8.7k questions on <a href=\"http://stackoverflow.com/tags/scrapy/info\">StackOverflow</a></li>\\n      </ul>\\n    </div>\\n    <div class=\"block-right\">\\n      <h2>Want to know more?</h2>\\n      <ul>\\n        <li><a href=\"http://doc.scrapy.org/en/1.5/intro/overview.html\">- Discover Scrapy at a glance</a></li>\\n        <li><a href=\"../companies/\">- Meet the companies using Scrapy</a></li>\\n      </ul>\\n\\n    </div>\\n  </div>\\n</div>\\n\\n      </div>\\n    </div>\\n\\n    <div class=\"footer\">\\n\\t<iframe src=\"https://ghbtns.com/github-btn.html?user=scrapy&repo=scrapy&type=watch&count=true\"\\n\\tallowtransparency=\"true\" frameborder=\"0\" scrolling=\"0\" width=\"110\" height=\"20\"></iframe>\\n\\t<iframe src=\"https://ghbtns.com/github-btn.html?user=scrapy&repo=scrapy&type=fork&count=true\"\\n\\tallowtransparency=\"true\" frameborder=\"0\" scrolling=\"0\" width=\"110\" height=\"20\"></iframe>\\n\\t<a class=\"twitter-follow-button\"\\n\\t  href=\"https://twitter.com/ScrapyProject\"\\n\\t  data-show-count=\"true\"\\n\\t  data-show-screen-name=\"false\"\\n\\t  data-lang=\"en\">\\n\\t@ScrapyProject\\n\\t</a>\\n\\t<script type=\"text/javascript\">\\n\\twindow.twttr = (function (d, s, id) {\\n\\t  var t, js, fjs = d.getElementsByTagName(s)[0];\\n\\t  if (d.getElementById(id)) return;\\n\\t  js = d.createElement(s); js.id = id;\\n\\t  js.src= \"https://platform.twitter.com/widgets.js\";\\n\\t  fjs.parentNode.insertBefore(js, fjs);\\n\\t  return window.twttr || (t = { _e: [], ready: function (f) { t._e.push(f) } });\\n\\t}(document, \"script\", \"twitter-wjs\"));\\n\\t</script>\\n\\n \\t<p>Maintained by <a href=\"https://scrapinghub.com/\">Scrapinghub</a> and <a href=\"https://github.com/scrapy/scrapy/graphs/contributors\">many other contributors</a></p>\\n</div>\\n\\n\\n  </body>\\n\\n</html>\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup\n",
    "\n",
    "Beautiful soup is a parsing library that uses different parsers. It can also navigate through a parsed document, and find what you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scrapy.org\n",
      "../download/\n",
      "../doc/\n",
      "../resources/\n",
      "../community/\n",
      "../companies/\n",
      "http://doc.scrapy.org/en/latest/faq.html\n",
      "https://github.com/scrapy/scrapy\n",
      "https://pypi.python.org/pypi/Scrapy\n",
      "https://pypi.python.org/pypi/Scrapy\n",
      "https://codecov.io/github/scrapy/scrapy?branch=master\n",
      "http://pypi.python.org/pypi/Scrapy\n",
      "https://anaconda.org/conda-forge/scrapy\n",
      "https://scrapinghub.com/scrapy-cloud/\n",
      "https://github.com/scrapy/scrapyd\n",
      "https://github.com/scrapy/scrapy\n",
      "https://twitter.com/ScrapyProject\n",
      "http://stackoverflow.com/tags/scrapy/info\n",
      "http://doc.scrapy.org/en/1.5/intro/overview.html\n",
      "../companies/\n",
      "https://twitter.com/ScrapyProject\n",
      "https://scrapinghub.com/\n",
      "https://github.com/scrapy/scrapy/graphs/contributors\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(contents, 'html.parser')\n",
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LXML\n",
    "\n",
    "Lxml is a high-performance, production-quality HTML and XML parsing library. We call it The Salad because you can rely on it to be good for you, no matter which diet you’re following.\n",
    "\n",
    "Beautiful soup vs lxml\n",
    "* If you need speed, go for lxml\n",
    "* If messy, use Beautiful Soup\n",
    "\n",
    "Not always true, and people generally prefer bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium\n",
    "\n",
    "In order to handle scraping javascript content, the above methods will not suffice. For example, some sites do dumb things like make you scroll down the page, or click a button to load content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapy\n",
    "\n",
    "Ok, we covered a lot just now. You’ve got Requests and Selenium for fetching HTML/XML from web pages. Then, you can use Beautiful Soup or lxml to parse it into useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
