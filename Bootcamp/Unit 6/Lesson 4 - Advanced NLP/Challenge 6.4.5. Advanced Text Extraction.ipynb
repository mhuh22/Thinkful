{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_newsgroups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View 20 newsgroups \n",
    "twenty_newsgroups.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first entry in dataset\n",
    "print(\"\\n\".join(twenty_newsgroups.data[0].split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Creating tf-idf matrix\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "twenty_newsgroups_tfidf = vectorizer.fit_transform(twenty_newsgroups.data)\n",
    "\n",
    "# Getting the word list.\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# Number of topics.\n",
    "ntopics=20\n",
    "\n",
    "# Linking words to topics\n",
    "def word_topic(tfidf,solution, wordlist):\n",
    "    \n",
    "    # Loading scores for each word on each topic/component.\n",
    "    words_by_topic=tfidf.T * solution\n",
    "\n",
    "    # Linking the loadings to the words in an easy-to-read way.\n",
    "    components=pd.DataFrame(words_by_topic,index=wordlist)\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Extracts the top N words and their loadings for each topic.\n",
    "def top_words(components, n_top_words):\n",
    "    n_topics = range(components.shape[1])\n",
    "    index= np.repeat(n_topics, n_top_words, axis=0)\n",
    "    topwords=pd.Series(index=index)\n",
    "    for column in range(components.shape[1]):\n",
    "        # Sort the column so that highest loadings are at the top.\n",
    "        sortedwords=components.iloc[:,column].sort_values(ascending=False)\n",
    "        # Choose the N highest loadings.\n",
    "        chosen=sortedwords[:n_top_words]\n",
    "        # Combine loading and index into a string.\n",
    "        chosenlist=chosen.index +\" \"+round(chosen,2).map(str) \n",
    "        topwords.loc[column]=chosenlist\n",
    "    return(topwords)\n",
    "\n",
    "# Number of words to look at for each topic.\n",
    "n_top_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "svd= TruncatedSVD(ntopics)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "twenty_newsgroups_lsa = lsa.fit_transform(twenty_newsgroups_tfidf)\n",
    "\n",
    "components_lsa = word_topic(twenty_newsgroups_tfidf, twenty_newsgroups_lsa, terms)\n",
    "\n",
    "topwords=pd.DataFrame()\n",
    "topwords['LSA']=top_words(components_lsa, n_top_words)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nu\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\nu\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA(n_topics=ntopics, \n",
    "          doc_topic_prior=None, # Prior = 1/n_documents\n",
    "          topic_word_prior=1/ntopics,\n",
    "          learning_decay=0.7, # Convergence rate.\n",
    "          learning_offset=10.0, # Causes earlier iterations to have less influence on the learning\n",
    "          max_iter=10, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          evaluate_every=-1, # Do not evaluate perplexity, as it slows training time.\n",
    "          mean_change_tol=0.001, # Stop updating the document topic distribution in the E-step when mean change is < tol\n",
    "          max_doc_update_iter=100, # When to stop updating the document topic distribution in the E-step even if tol is not reached\n",
    "          n_jobs=-1, # Use all available CPUs to speed up processing time.\n",
    "          verbose=0, # amount of output to give while iterating\n",
    "          random_state=0\n",
    "         )\n",
    "\n",
    "twenty_newsgroups_lda = lda.fit_transform(twenty_newsgroups_tfidf) \n",
    "\n",
    "components_lda = word_topic(twenty_newsgroups_tfidf, twenty_newsgroups_lda, terms)\n",
    "\n",
    "topwords['LDA']=top_words(components_lda, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(alpha=0.0, \n",
    "          init='nndsvdar', # how starting value are calculated\n",
    "          l1_ratio=0.0, # Sets whether regularization is L2 (0), L1 (1), or a combination (values between 0 and 1)\n",
    "          max_iter=200, # when to stop even if the model is not converging (to prevent running forever)\n",
    "          n_components=ntopics, \n",
    "          random_state=0, \n",
    "          solver='cd', # Use Coordinate Descent to solve\n",
    "          tol=0.0001, # model will stop if tfidf-WH <= tol\n",
    "          verbose=0 # amount of output to give while iterating\n",
    "         )\n",
    "twenty_newsgroups_nmf = nmf.fit_transform(twenty_newsgroups_tfidf) \n",
    "\n",
    "components_nmf = word_topic(twenty_newsgroups_tfidf, twenty_newsgroups_nmf, terms)\n",
    "\n",
    "topwords['NNMF']=top_words(components_nmf, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "                  LSA                LDA          NNMF\n",
      "0          edu 222.97           edu 2.34      car 2.45\n",
      "0          com 154.56           com 1.58      edu 1.74\n",
      "0        subject 95.9       subject 1.09      com 1.72\n",
      "0         lines 95.12         lines 1.08     bike 1.24\n",
      "0  organization 94.05  organization 1.07     like 1.08\n",
      "0        writes 91.32    university 0.96     just 1.06\n",
      "0       article 89.22        writes 0.86       don 1.0\n",
      "0    university 84.47       article 0.86     good 0.99\n",
      "0           don 79.59            ca 0.84  article 0.97\n",
      "0          like 78.45       posting 0.83   writes 0.96\n",
      "Topic 1:\n",
      "                LSA                LDA             NNMF\n",
      "1         god 47.18            edu 2.3         god 8.44\n",
      "1      people 24.58           com 1.62       jesus 3.67\n",
      "1       jesus 22.46       subject 1.08       bible 2.37\n",
      "1       bible 14.77         lines 1.07         edu 2.32\n",
      "1   christian 14.15  organization 1.06      people 2.31\n",
      "1  christians 14.12    university 0.94     believe 2.04\n",
      "1     believe 12.71        writes 0.86  christians 1.97\n",
      "1      christ 11.28       posting 0.85   christian 1.95\n",
      "1       faith 11.26       article 0.85       faith 1.87\n",
      "1      church 11.01          host 0.82      christ 1.73\n",
      "Topic 2:\n",
      "                LSA                LDA             NNMF\n",
      "2          com 28.5           edu 2.29         key 5.46\n",
      "2         key 27.57           com 1.58     clipper 4.25\n",
      "2      clipper 22.0       subject 1.06  encryption 4.22\n",
      "2        chip 20.83         lines 1.05        chip 4.12\n",
      "2  encryption 19.67  organization 1.04      escrow 2.49\n",
      "2  government 15.34    university 0.92        keys 2.42\n",
      "2      netcom 13.24        writes 0.86  government 2.12\n",
      "2         keys 12.6       article 0.85         com 1.92\n",
      "2       escrow 11.8       posting 0.82   algorithm 1.61\n",
      "2        access 9.1          host 0.79    security 1.55\n",
      "Topic 3:\n",
      "             LSA                LDA          NNMF\n",
      "3      god 31.22           edu 2.32   windows 4.2\n",
      "3  windows 24.42           com 1.57      edu 2.49\n",
      "3    drive 14.84       subject 1.07      dos 1.92\n",
      "3     card 14.69         lines 1.06   window 1.89\n",
      "3    jesus 13.67  organization 1.05     file 1.81\n",
      "3       dos 13.4    university 0.94      com 1.75\n",
      "3     scsi 11.89        writes 0.85     card 1.71\n",
      "3    window 10.4       article 0.85      use 1.56\n",
      "3     file 10.26       posting 0.84     files 1.4\n",
      "3       pc 10.25          host 0.81  program 1.32\n",
      "Topic 4:\n",
      "               LSA                LDA           NNMF\n",
      "4        edu 19.64           edu 2.29      pitt 4.47\n",
      "4       pitt 17.18           com 1.57       geb 4.32\n",
      "4         cs 16.38       subject 1.07    gordon 4.13\n",
      "4      gordon 14.7         lines 1.06     banks 4.13\n",
      "4        geb 14.43  organization 1.05        cs 2.39\n",
      "4       banks 14.1    university 0.94       edu 2.08\n",
      "4        key 10.32        writes 0.86     cadre 1.47\n",
      "4         god 9.76       article 0.85     n3jxp 1.46\n",
      "4      clipper 7.7       posting 0.82       dsl 1.46\n",
      "4  encryption 7.64          host 0.82  chastity 1.46\n",
      "Topic 5:\n",
      "                LSA               LDA               NNMF\n",
      "5         edu 30.45           edu 2.6           edu 6.77\n",
      "5      israel 16.46          com 1.77    university 2.25\n",
      "5     israeli 12.92           ax 1.31            cs 1.87\n",
      "5       state 11.78      subject 1.23  organization 1.76\n",
      "5         cwru 10.6        lines 1.22       subject 1.76\n",
      "5  university 10.43  organization 1.2         lines 1.75\n",
      "5    cleveland 9.89   university 1.09       article 1.75\n",
      "5         ohio 9.45      article 0.95       posting 1.74\n",
      "5         jews 9.03       writes 0.94        writes 1.71\n",
      "5      freenet 6.48      posting 0.94           host 1.7\n",
      "Topic 6:\n",
      "             LSA                LDA               NNMF\n",
      "6      com 56.13            edu 2.3           com 6.73\n",
      "6    keith 13.42           com 1.58        netcom 1.94\n",
      "6  caltech 11.74       subject 1.07        writes 1.78\n",
      "6      sgi 11.54         lines 1.06           edu 1.77\n",
      "6       hp 10.06  organization 1.05       article 1.75\n",
      "6    writes 9.94    university 0.93        access 1.54\n",
      "6   article 9.79        writes 0.85       subject 1.49\n",
      "6    netcom 9.31       article 0.85  organization 1.48\n",
      "6   posting 9.22       posting 0.83         lines 1.47\n",
      "6      nntp 8.92           host 0.8            hp 1.36\n",
      "Topic 7:\n",
      "            LSA                  LDA             NNMF\n",
      "7     com 22.57           edu 266.24      people 2.59\n",
      "7   israel 9.72            com 190.4         gun 2.31\n",
      "7     pitt 8.62       subject 119.38          edu 2.2\n",
      "7    drive 8.38         lines 118.65         don 1.76\n",
      "7   gordon 8.13  organization 117.33         com 1.72\n",
      "7      geb 7.73        writes 107.84       think 1.51\n",
      "7  israeli 7.73       article 106.99        just 1.36\n",
      "7   turkish 7.7    university 104.65        like 1.36\n",
      "7    banks 7.39        posting 95.48        guns 1.32\n",
      "7     scsi 7.25           like 94.48  government 1.24\n",
      "Topic 8:\n",
      "               LSA                LDA         NNMF\n",
      "8      drive 15.22           edu 2.56     nasa 4.0\n",
      "8       scsi 15.15           com 1.79   space 2.92\n",
      "8         ide 8.11       subject 1.17     gov 2.76\n",
      "8        game 6.47         lines 1.16    henry 1.4\n",
      "8  controller 6.12  organization 1.15      edu 1.3\n",
      "8       apple 5.75          host 0.98     jpl 1.08\n",
      "8      drives 5.58    university 0.97  toronto 1.0\n",
      "8         bus 5.43       article 0.95  alaska 0.94\n",
      "8        team 5.06        writes 0.94    moon 0.87\n",
      "8        card 4.93       cooling 0.93     com 0.79\n",
      "Topic 9:\n",
      "              LSA                LDA             NNMF\n",
      "9      nasa 18.34           edu 2.27        scsi 5.72\n",
      "9      scsi 18.27           com 1.57        drive 3.4\n",
      "9     drive 16.26       subject 1.05         ide 2.56\n",
      "9     space 14.46         lines 1.05  controller 1.53\n",
      "9       gov 12.76  organization 1.03      drives 1.33\n",
      "9        ide 8.93    university 0.91          bus 1.3\n",
      "9      henry 6.64        writes 0.85         hard 1.2\n",
      "9  controller 6.4       article 0.84         edu 1.17\n",
      "9     alaska 6.34       posting 0.82         mac 1.14\n",
      "9     drives 6.09          host 0.79         disk 1.1\n",
      "Topic 10:\n",
      "               LSA                LDA            NNMF\n",
      "10     keith 15.31           edu 2.29      keith 3.84\n",
      "10   caltech 13.29           com 1.57    caltech 3.15\n",
      "10        sgi 8.88       subject 1.07    livesey 2.45\n",
      "10   morality 8.61         lines 1.06        sgi 2.43\n",
      "10         uk 7.99  organization 1.05   morality 2.13\n",
      "10    livesey 7.85    university 0.98        edu 1.82\n",
      "10  objective 7.32        writes 0.88    solntze 1.72\n",
      "10        cco 6.41       article 0.85        wpd 1.72\n",
      "10       team 6.27       posting 0.83  objective 1.58\n",
      "10      space 6.15           host 0.8        jon 1.55\n",
      "Topic 11:\n",
      "              LSA                LDA           NNMF\n",
      "11   israel 18.61           edu 2.54     israel 5.4\n",
      "11       ca 18.28           com 1.66   israeli 3.91\n",
      "11      com 17.96       subject 1.17      jews 2.46\n",
      "11  israeli 14.36         lines 1.15      arab 1.83\n",
      "11      jews 9.81  organization 1.13       edu 1.54\n",
      "11      arab 6.37    university 1.09  lebanese 1.33\n",
      "11    jewish 6.23        writes 0.94     arabs 1.28\n",
      "11      jake 6.05       posting 0.92     peace 1.19\n",
      "11   freenet 5.38        article 0.9      jake 1.17\n",
      "11     mcgill 5.2          host 0.89    jewish 1.13\n",
      "Topic 12:\n",
      "               LSA                LDA            NNMF\n",
      "12       com 13.63           edu 2.33   armenian 3.05\n",
      "12   turkish 10.72            com 1.6    turkish 2.97\n",
      "12   armenian 9.82       subject 1.08  armenians 2.64\n",
      "12  armenians 9.03         lines 1.07    armenia 1.89\n",
      "12        edu 8.95  organization 1.06      argic 1.78\n",
      "12     andrew 8.15    university 0.92     serdar 1.76\n",
      "12        cmu 7.08        writes 0.88      turks 1.58\n",
      "12    armenia 7.07       article 0.87   genocide 1.32\n",
      "12      apple 7.04       posting 0.84     turkey 1.28\n",
      "12     serdar 6.59          host 0.81       zuma 1.16\n",
      "Topic 13:\n",
      "               LSA                 LDA             NNMF\n",
      "13      ohio 15.29           edu 53.34        ohio 4.11\n",
      "13      state 9.67           god 36.86       state 3.34\n",
      "13        acs 9.48            com 36.6       magnus 3.1\n",
      "13     magnus 9.41        people 27.94         acs 2.76\n",
      "13         ca 8.95        writes 26.07         edu 1.82\n",
      "13  cleveland 7.95       article 24.02  university 0.86\n",
      "13         __ 7.83       subject 20.07      article 0.7\n",
      "13        ___ 7.27           don 19.97     posting 0.59\n",
      "13       cwru 6.88         lines 19.46        nntp 0.59\n",
      "13         uk 6.51  organization 19.22        host 0.59\n",
      "Topic 14:\n",
      "               LSA                LDA          NNMF\n",
      "14   windows 16.62           edu 2.27     team 2.45\n",
      "14     access 12.1           com 1.57       ca 2.36\n",
      "14      digex 8.63       subject 1.06      game 2.2\n",
      "14  cleveland 7.93         lines 1.05      edu 1.84\n",
      "14    sandvik 7.53  organization 1.04   hockey 1.63\n",
      "14      apple 7.26    university 0.92  players 1.48\n",
      "14       card 7.22        writes 0.85    games 1.41\n",
      "14       cwru 7.08       article 0.84     year 1.41\n",
      "14        dos 6.35       posting 0.83     play 1.28\n",
      "14      mouse 6.15           host 0.8   season 1.22\n",
      "Topic 15:\n",
      "               LSA                LDA             NNMF\n",
      "15  columbia 14.44           edu 2.44     sandvik 4.61\n",
      "15        cc 12.36           com 1.68       apple 3.05\n",
      "15     state 11.27       subject 1.15        kent 2.74\n",
      "15      ohio 10.77         lines 1.14      newton 2.14\n",
      "15     magnus 8.56  organization 1.13         com 1.36\n",
      "15        acs 8.38    university 0.97       ksand 0.94\n",
      "15        gld 7.92        writes 0.91       alink 0.94\n",
      "15     cunixb 7.48        article 0.9         edu 0.82\n",
      "15       gary 5.74       posting 0.89  cookamunga 0.81\n",
      "15    windows 5.68          host 0.86      tourist 0.8\n",
      "Topic 16:\n",
      "              LSA                LDA          NNMF\n",
      "16    apple 15.43           edu 2.45  columbia 3.8\n",
      "16       uk 14.57           com 1.62      gld 3.12\n",
      "16  sandvik 12.91       subject 1.11        cc 2.9\n",
      "16       ac 10.67         lines 1.11   cunixb 2.56\n",
      "16      kent 8.32  organization 1.09     dare 1.81\n",
      "16    newton 6.22    university 0.97       edu 1.8\n",
      "16       gov 6.08       posting 0.89     gary 1.77\n",
      "16       nasa 6.0        writes 0.88     jets 0.64\n",
      "16       gun 4.96       article 0.88     domi 0.61\n",
      "16    window 4.29          host 0.85    cunixc 0.6\n",
      "Topic 17:\n",
      "              LSA                LDA            NNMF\n",
      "17       cs 10.87           edu 2.31  cleveland 4.65\n",
      "17      edu 10.33           com 1.57       cwru 4.19\n",
      "17     henry 9.75       subject 1.07    freenet 3.15\n",
      "17   toronto 9.15         lines 1.06         edu 3.1\n",
      "17  virginia 9.07  organization 1.05        ins 2.24\n",
      "17     apple 7.63    university 0.92    reserve 2.22\n",
      "17   georgia 6.24        writes 0.87     western 2.2\n",
      "17     state 6.14       article 0.85       case 1.72\n",
      "17      card 5.92       posting 0.83         po 1.52\n",
      "17   sandvik 5.47           host 0.8        usa 1.41\n",
      "Topic 18:\n",
      "             LSA                LDA          NNMF\n",
      "18       uk 13.6           edu 2.27  stratus 4.19\n",
      "18  access 11.64           com 1.59       sw 2.24\n",
      "18     car 10.91       subject 1.06      cdt 2.12\n",
      "18      ac 10.88         lines 1.05      com 2.04\n",
      "18    henry 9.23  organization 1.04      fbi 1.74\n",
      "18    digex 8.71    university 0.91      edu 1.61\n",
      "18  toronto 8.02        writes 0.85     batf 1.51\n",
      "18     bike 7.74       article 0.84     udel 1.44\n",
      "18       ca 7.46       posting 0.83     roby 1.39\n",
      "18      pat 5.54           host 0.8   rocket 1.08\n",
      "Topic 19:\n",
      "               LSA                LDA               NNMF\n",
      "19        uk 20.42            ax 5.01             uk 5.6\n",
      "19        ac 15.79           edu 2.27            ac 4.29\n",
      "19    access 14.27           com 1.57           ___ 1.04\n",
      "19  virginia 11.57       subject 1.05            __ 1.03\n",
      "19      digex 9.38         lines 1.05           edu 0.92\n",
      "19         cs 8.96  organization 1.03     university 0.9\n",
      "19       uiuc 8.62    university 0.91           com 0.89\n",
      "19     andrew 8.52        writes 0.85       subject 0.85\n",
      "19        cmu 8.17       article 0.84         lines 0.84\n",
      "19        pat 6.37       posting 0.82  organization 0.82\n"
     ]
    }
   ],
   "source": [
    "for topic in range(ntopics):\n",
    "    print('Topic {}:'.format(topic))\n",
    "    print(topwords.loc[topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6a23e3a91369>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Labeling the data by method and providing an ordering variable for graphing purposes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mwordloadings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'method'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LSA'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'LDA'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'NNMF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mwordloadings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loading'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3115\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3191\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3192\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3387\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3388\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3389\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3390\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m   3996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3997\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3998\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Length of values does not match length of '\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4000\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "# The words to look at.\n",
    "targetwords=['marriage','love','emma','oh']\n",
    "\n",
    "# Storing the loadings.\n",
    "wordloadings=pd.DataFrame(columns=targetwords)\n",
    "\n",
    "# For each word, extracting and string the loadings for each method.\n",
    "for word in targetwords:\n",
    "    loadings=components_lsa.loc[word].append(\n",
    "        components_lda.loc[word]).append(\n",
    "            components_nmf.loc[word])\n",
    "    wordloadings[word]=loadings\n",
    "\n",
    "# Labeling the data by method and providing an ordering variable for graphing purposes. \n",
    "wordloadings['method']=np.repeat(['LSA','LDA','NNMF'], 5, axis=0)\n",
    "wordloadings['loading']=[0,1,2,3,4]*3\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "for word in targetwords:\n",
    "    sns.barplot(x=\"method\", y=word, hue=\"loading\", data=wordloadings)\n",
    "    plt.title(word)\n",
    "    plt.ylabel(\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
